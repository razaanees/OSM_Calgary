{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Street Map Case Study - Calgary, Alberta, Canada\n",
    "\n",
    "By: Raza Anees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Area\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"https://www.openstreetmap.org/relation/3227127#map=10/51.0289/-114.0875\">Calgary City Boundary</a></li>\n",
    "    <li><a href=\"https://mapzen.com/data/metro-extracts/\">Calgary Metro Extract</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be analyzing the open street map data for Calgary, Alberta. This is my home town and it is a sprawling urban centre with more than 1.1 million people. I'm interested to see some of the descriptions for the data in the city and how much data has been contributed to date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Libraries and open/save paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET #for parsing the XML file\n",
    "from pprint import pprint #for \"pretty\" results\n",
    "from collections import defaultdict #for initializing keys in dictionaries\n",
    "import re #for using regular expressions\n",
    "import csv #for parsing and writing CSVs\n",
    "import codecs\n",
    "import cerberus # for validating\n",
    "import schema # for setting the schema\n",
    "\n",
    "OSM_FILE = \"calgary_canada.osm\"\n",
    "SAMPLE_OSM = \"calgary_sample.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODES_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a small sample of the file for Auditing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 50 #parameter: take every k-th level\n",
    "\n",
    "def get_element(osm_file, tags=(\"node\", \"way\", \"relation\")):\n",
    "    context = iter(ET.iterparse(osm_file, events = ('start', 'end')))\n",
    "    _,root = next(context)\n",
    "    \n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#obtain every k'th level and write to a file for later analysis\n",
    "with open(SAMPLE_OSM, 'w') as samp:\n",
    "    samp.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n')\n",
    "    samp.write(\"<osm>\\n \")\n",
    "    \n",
    "    for i, elem in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            samp.write(ET.tostring(elem, encoding='utf-8'))\n",
    "    samp.write('</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the name of all of the \"k\" types under the \"tag\" tag of the nodes. These types will be audited to identify any dirty data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_types(xml_file, tags):\n",
    "    types = []\n",
    "    node_types = set()\n",
    "    way_types = {}\n",
    "    for elem in get_element(xml_file, tags):\n",
    "            for child in elem:\n",
    "                if child.tag == \"tag\":\n",
    "                    node_types.add(child.get('k'))\n",
    "    return node_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['addr:city',\n",
      "     'addr:housenumber',\n",
      "     'addr:postcode',\n",
      "     'addr:province',\n",
      "     'addr:street',\n",
      "     'amenity',\n",
      "     'barrier',\n",
      "     'created_by',\n",
      "     'crossing',\n",
      "     'healthcare',\n",
      "     'highway',\n",
      "     'leisure',\n",
      "     'name',\n",
      "     'natural',\n",
      "     'office',\n",
      "     'place',\n",
      "     'power',\n",
      "     'railway',\n",
      "     'ref',\n",
      "     'shop',\n",
      "     'source',\n",
      "     'sport',\n",
      "     'website'])\n"
     ]
    }
   ],
   "source": [
    "tags = ('node')\n",
    "n = get_types(SAMPLE_OSM, tags)\n",
    "pprint(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Avenue',\n",
      "     'Common',\n",
      "     'Crescent',\n",
      "     'Dr.',\n",
      "     'Drive',\n",
      "     'Estates',\n",
      "     'Glenmore',\n",
      "     'Highway',\n",
      "     'Hill',\n",
      "     'Hills',\n",
      "     'Manor',\n",
      "     'Meadows',\n",
      "     'Park',\n",
      "     'Pine',\n",
      "     'Road',\n",
      "     'Street',\n",
      "     'Trail',\n",
      "     'Twintree',\n",
      "     'Valley',\n",
      "     'Way',\n",
      "     'Wood'])\n",
      "\n",
      "\n",
      "set(['',\n",
      "     '51A',\n",
      "     'Boulevard',\n",
      "     'Circle',\n",
      "     'Crescent',\n",
      "     'Drive',\n",
      "     'NE',\n",
      "     'NW',\n",
      "     'Northwest',\n",
      "     'Park',\n",
      "     'Place',\n",
      "     'Road',\n",
      "     'SE',\n",
      "     'SW',\n",
      "     'Southwest',\n",
      "     'Way',\n",
      "     'West'])\n"
     ]
    }
   ],
   "source": [
    "#finding problems in the addresses\n",
    "#this is one example of finding all the variations in the street names\n",
    "#similar scripts were executed to find the other problems outlined below\n",
    "street = set() #for storing all of the different kinds of street names entered in the dataset\n",
    "street2 = set()\n",
    "\n",
    "for elem in get_element(SAMPLE_OSM, tags=('node', 'way')):\n",
    "        for child in elem:\n",
    "            if child.tag == \"tag\":\n",
    "                if child.attrib['k'] == 'addr:street':\n",
    "                    q = child.attrib['v'].split(' ')\n",
    "                    if len(q) > 1:\n",
    "                        street.add(q[1])\n",
    "                    if len(q) > 2:\n",
    "                        street2.add(q[2])\n",
    "pprint(street)\n",
    "print '\\n'\n",
    "pprint(street2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>A few of the above \"k\" attributes were explored for potential errors or inconsistencies in the data. The following section details the problems encountered and the solutions used.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Encountered in the Map\n",
    "\n",
    "<ul>\n",
    "    <li>Calgary with uppercase and lowercase 'c'</li>\n",
    "    <li>Two different ways of writing the province (\"AB\" and \"Alberta\"). Contains an address from the province of Ontario that will need to be removed.</li>\n",
    "    <li>Different ways of representing the quadrants in street names (\"se\", \"SE\", \"S.E.\", \"SouthEast\")</li>\n",
    "    <li>Different ways of representing the same street names (\"Dr.\", \"Drive\"). Some street names have a semi-colon in the same entry.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These problems will be solved after the data in shaped into the desired schema in a python dictionary format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape Element into Schema and Correct Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set up the headings for node and way dictionaries and eventual csv transformation\n",
    "\n",
    "NODE_FIELDS = ['id', 'user', 'uid', 'version', 'lat', 'lon', 'timestamp', 'changeset']\n",
    "NODE_TAG_FIELDS = ['id', 'key', 'value', 'type']\n",
    "\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "\n",
    "key_re = re.compile(r'(.*?(?=:))\\:(\\S.+)') #regular expression for determining if colon exists in entry and to seperate \n",
    "#                                         # expression after first colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function to shape the node and way tags\n",
    "\n",
    "def shape_tag(element, default_type = 'regular', key_re = key_re):\n",
    "    tags = []\n",
    "    \n",
    "    for child in element:\n",
    "        if child.tag == 'tag':\n",
    "            tag= {}\n",
    "            tag['id'] = element.attrib['id']\n",
    "            tag['key'] = child.attrib['k']\n",
    "            tag['value'] = child.attrib['v']\n",
    "            tag['type'] = default_type\n",
    "            \n",
    "            key = key_re.search(child.attrib['k'])\n",
    "            if key:\n",
    "                tag['key'] = key.group(2)\n",
    "                tag['type'] = key.group(1)\n",
    "            \n",
    "            tags.append(tag.copy())\n",
    "    return tags\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shape_element(element, node_fields = NODE_FIELDS, way_fields = WAY_FIELDS, way_nodes = WAY_NODES_FIELDS, default_type = 'regular'):\n",
    "    \n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []\n",
    "    \n",
    "    if element.tag == \"node\":\n",
    "        for field in node_fields:\n",
    "            node_attribs[field] = element.attrib[field]\n",
    "        \n",
    "        tags = shape_tag(element)\n",
    "                \n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "\n",
    "    elif element.tag == 'way':\n",
    "        for field in way_fields:\n",
    "            way_attribs[field] = element.attrib[field]\n",
    "        \n",
    "        tags = shape_tag(element)\n",
    "        \n",
    "        i = 0\n",
    "        for child in element:\n",
    "            if child.tag == 'nd':\n",
    "                i += 1\n",
    "                way_node = {}\n",
    "                way_node['id'] = element.attrib['id']\n",
    "                way_node['node_id'] = child.attrib['ref']\n",
    "                way_node['position'] = i\n",
    "                way_nodes.append(way_node.copy())\n",
    "        \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#function for correcting values in a dictionary when a comparison map is presented\n",
    "\n",
    "def correct_values(el, mapp):\n",
    "    for tag in el['node_tags']:\n",
    "        if tag['value'] in mapp:\n",
    "            tag['value'] = mapp[tag['value']]\n",
    "    return el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set up lists to store the shaped node and way elements\n",
    "\n",
    "nodes = []\n",
    "ways = []\n",
    "\n",
    "for elem in get_element(OSM_FILE):\n",
    "    el = shape_element(elem)\n",
    "    if elem.tag == 'node':\n",
    "        nodes.append(el.copy())\n",
    "    elif elem.tag == 'way':\n",
    "        ways.append(el.copy())\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fixing the city names\n",
    "\n",
    "mapping = {'calgary':'Calgary',\n",
    "          'Calary': 'Calgary',\n",
    "          'Calgary, AB': 'Calgary',\n",
    "          'Foothills No. 31, M.D. of': 'Foothills County',\n",
    "          'Rocky View No. 44, M.D. of': 'Rocky View County',\n",
    "          'Rocky View': 'Rocky View County',\n",
    "          'Rockyview County': 'Rocky View County'}\n",
    "\n",
    "for el in nodes:\n",
    "    el = correct_values(el, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fixing province name\n",
    "\n",
    "mapping = {'AB': 'Alberta',\n",
    "          'Albertaa': 'Alberta',\n",
    "          'ab': 'Alberta',\n",
    "          'alberta': 'Alberta'}\n",
    "#delete\n",
    "de = ['ON']\n",
    "\n",
    "for el in nodes:\n",
    "    el = correct_values(el, mapping)\n",
    "    for tag in el['node_tags']:\n",
    "        if tag['value'] in de:\n",
    "            nodes.remove(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fixing all street and quadrant names\n",
    "\n",
    "mapping = {'Northeast': 'NE',\n",
    "          'NE;Trans-Canada': 'NE',\n",
    "          'Northwest':'NW',\n",
    "          'Southwest': 'SW',\n",
    "          'South-west': 'SW',\n",
    "          'Southeast': 'SE',\n",
    "          'N.E.': 'NE',\n",
    "          'n.e.\\n': 'NE',\n",
    "          'N.W.':'NW',\n",
    "          'N.W': 'NW',\n",
    "          'nw': 'NW',\n",
    "          'se': 'SE',\n",
    "          'S.E': 'SE',\n",
    "          'S.W': 'SE',\n",
    "          'South-east': 'SE',\n",
    "          'St': 'Street',\n",
    "          'st': 'Street',\n",
    "          'Rd': 'Road',\n",
    "          'rise': 'Rise',\n",
    "          'N': 'North',\n",
    "          'Blvd.': 'Boulevard',\n",
    "          'Dr': 'Drive',\n",
    "          'NW;Trans-Canada': 'NW',\n",
    "          'Rroad': 'Road',\n",
    "          'S': 'South',\n",
    "          'Blvd.': 'Boulevard',\n",
    "          'Dr.': 'Drive',\n",
    "          'creek': 'Creek',\n",
    "          'Tr': 'Trail'}\n",
    "\n",
    "#find the third word in a street name\n",
    "quad = re.compile(r'\\b\\S+.?$',re.IGNORECASE)\n",
    "\n",
    "for node in nodes:\n",
    "    for tag in node['node_tags']:\n",
    "        if tag['key'] == (\"street\" or \"street:name\"):\n",
    "            name = tag['value'].split(' ')\n",
    "            for i, word in enumerate(name):\n",
    "                if word in mapping:\n",
    "                    name[i] = mapping[word]\n",
    "                tag['value'] = ' '.join(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below checks if all of the undesired data values were cleaned or removed as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are all of the province in this data set: \n",
      "set(['Alberta'])\n",
      "\n",
      "\n",
      "These are all of the city in this data set: \n",
      "set(['',\n",
      "     '#145',\n",
      "     '15',\n",
      "     '2',\n",
      "     '20',\n",
      "     '596',\n",
      "     '6',\n",
      "     '7',\n",
      "     '8',\n",
      "     'Airdrie',\n",
      "     'Calgary',\n",
      "     'Chestermere',\n",
      "     'Cochrane',\n",
      "     'County',\n",
      "     'Creek',\n",
      "     'I.D.',\n",
      "     'Okotoks'])\n",
      "\n",
      "\n",
      "These are all of the street in this data set: \n",
      "set(['',\n",
      "     '204A',\n",
      "     '205A',\n",
      "     '21',\n",
      "     '210',\n",
      "     '210A',\n",
      "     '210B',\n",
      "     '224',\n",
      "     '232',\n",
      "     '234',\n",
      "     '50A',\n",
      "     '51',\n",
      "     '51A',\n",
      "     '52',\n",
      "     '52A',\n",
      "     '66',\n",
      "     'AB',\n",
      "     'Avenue',\n",
      "     'Boulevard',\n",
      "     'Close',\n",
      "     'Common',\n",
      "     'Court',\n",
      "     'Crescent',\n",
      "     'Drive',\n",
      "     'East',\n",
      "     'Gate',\n",
      "     'Highway',\n",
      "     'Hollow',\n",
      "     'NE',\n",
      "     'NW',\n",
      "     'North',\n",
      "     'Park',\n",
      "     'Place',\n",
      "     'Point',\n",
      "     'Rise',\n",
      "     'Road',\n",
      "     'SE',\n",
      "     'SW',\n",
      "     'South',\n",
      "     'Street',\n",
      "     'Trail',\n",
      "     'Way',\n",
      "     'West',\n",
      "     'high_mast'])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_test = set()\n",
    "c_test = set()\n",
    "s_test = set()\n",
    "\n",
    "def check_values(value, sett, elements = nodes):\n",
    "    for elem in nodes:\n",
    "        for tag in elem['node_tags']:\n",
    "            if value in tag[\"key\"]:\n",
    "                w = tag['value'].split(' ')\n",
    "                sett.add(w[-1])\n",
    "    print \"These are all of the {} in this data set: \".format(value)\n",
    "    pprint(sett)\n",
    "    print '\\n'\n",
    "\n",
    "check_values('province', p_test)\n",
    "check_values('city', c_test)\n",
    "check_values('street', s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing information from XML file into CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Set up validator and unicode dictionary writer functions for transformation of clean data into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SCHEMA = schema.schema\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement type {0} has errors: \\n{1}\"\n",
    "        error_string = (\n",
    "            \"{0}: {1}\".format(k,v if isinstance(v, str) else ', '.join(v)) for k,v in errors.iteritems()\n",
    "        )\n",
    "    \n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(fields, '\\n'.join(error_string))\n",
    "    )\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "                k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k,v in row.iteritems()\n",
    "            })\n",
    "    \n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert Python dictionaries into csv files after validating\n",
    "\n",
    "with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "    codecs.open(NODES_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "    codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "    codecs.open(WAY_NODES_PATH, 'w') as ways_nodes_file, \\\n",
    "    codecs.open(WAY_TAGS_PATH, 'w') as ways_tags_file:\n",
    "        \n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        nodes_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAG_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        ways_nodes_writer = UnicodeDictWriter(ways_nodes_file, WAY_NODES_FIELDS)\n",
    "        ways_tags_writer = UnicodeDictWriter(ways_tags_file, WAY_TAGS_FIELDS)\n",
    "        \n",
    "        nodes_writer.writeheader()\n",
    "        nodes_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        ways_nodes_writer.writeheader()\n",
    "        ways_tags_writer.writeheader()\n",
    "        \n",
    "        validate = False\n",
    "        validator = cerberus.Validator()\n",
    "        \n",
    "        for node in nodes:\n",
    "            if validate:\n",
    "                validate_element(node, validator)\n",
    "            \n",
    "            nodes_writer.writerow(node['node'])\n",
    "            nodes_tags_writer.writerows(node['node_tags'])\n",
    "        \n",
    "        for way in ways:\n",
    "            if validate:\n",
    "                validate_element(way, validator)\n",
    "            \n",
    "            ways_writer.writerow(way['way'])\n",
    "            ways_nodes_writer.writerows(way['way_nodes'])\n",
    "            ways_tags_writer.writerows(way['way_tags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#connect sqlite to python to run and modify queries in jupyter\n",
    "\n",
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "\n",
    "def return_query(query,alter=False): \n",
    "    cal_db = sql.connect(\"calgary_canada.db\")\n",
    "    c = cal_db.cursor()\n",
    "    c.execute(query)\n",
    "    if alter:\n",
    "        c.commit()\n",
    "    results = c.fetchall()\n",
    "    r = pd.DataFrame(results)\n",
    "    cal_db.close()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calgary_canada.db ............... 109 MB<br>\n",
    "calgary_canada.osm .............. 165 MB<br>\n",
    "nodes.csv ........................... 65 MB<br>\n",
    "nodes_tags.csv .................. 2.4 MB<br>\n",
    "ways.csv ........................ 8 MB<br>\n",
    "ways_nodes.csv .................. 18 MB<br>\n",
    "ways_tags.csv ................... 14 MB<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QUERY = \"SELECT count(*) FROM nodes;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"num\">755292</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QUERY = \"SELECT count(*) FROM way;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p class='num'>91236</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QUERY1 = \"SELECT COUNT(DISTINCT(uid)) FROM nodes\"\n",
    "\n",
    "QUERY2 = \"SELECT COUNT(DISTINCT(uid)) FROM way\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nodes:\n",
    "<p class='num'> 778</p>\n",
    "\n",
    "#### Ways:\n",
    "<p class='num'>619</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 node contributing users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0       1\n",
      "0      sbrown  198212\n",
      "1   Zippanova   68927\n",
      "2      abDoug   45413\n",
      "3  markbegbie   41948\n",
      "4     dbo-osm   34347\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT user, count(user) AS Total\n",
    "FROM Nodes\n",
    "GROUP BY user\n",
    "ORDER BY Total DESC\n",
    "LIMIT 5;\n",
    "'''\n",
    "\n",
    "a = return_query(QUERY)\n",
    "\n",
    "print a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the node(s) with the most tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0   1\n",
      "0  51970215  24\n",
      "1  51971748  24\n",
      "2  51972854  24\n",
      "3  51969828  23\n",
      "4  51970028  23\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT nodes.id, count(node_tags.id) AS Count\n",
    "FROM nodes JOIN node_tags\n",
    "ON nodes.id = node_tags.id\n",
    "GROUP BY nodes.id\n",
    "ORDER BY count DESC\n",
    "LIMIT 5;\n",
    "'''\n",
    "print return_query(QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population centre with the most unique nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0    1\n",
      "0            Calgary  518\n",
      "1  Rocky View County  243\n",
      "2        Bragg Creek  179\n",
      "3    Kananaskis I.D.   81\n",
      "4    Tsuu T'ina #145   76\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT node_tags.value, count(*) as num\n",
    "FROM node_tags\n",
    "WHERE key='city'\n",
    "GROUP BY value\n",
    "ORDER BY num DESC\n",
    "LIMIT 5;\n",
    "'''\n",
    "\n",
    "print return_query(QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The City of Calgary has the most unique nodes, as expected, although the difference in the number of unique nodes is not as large as it should be. This indicates that \"tag\" tags have not been added to many nodes yet or the addresses of those nodes do not include the city name yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadrant of the City of Calgary with the most addresses in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QUERY_NE = '''\n",
    "SELECT count(*) AS NE\n",
    "FROM (SELECT value, count(value) as sum\n",
    "FROM node_tags\n",
    "WHERE key = 'street' AND value LIKE '%NE'\n",
    "GROUP BY value);\n",
    "'''\n",
    "\n",
    "QUERY_NW = '''\n",
    "SELECT count(*) AS NW\n",
    "FROM (SELECT value, count(value) as sum\n",
    "FROM node_tags\n",
    "WHERE key = 'street' AND value LIKE '%NW'\n",
    "GROUP BY value);\n",
    "'''\n",
    "\n",
    "QUERY_SE = '''\n",
    "SELECT count(*) AS SE\n",
    "FROM (SELECT value, count(value) as sum\n",
    "FROM node_tags\n",
    "WHERE key = 'street' AND value LIKE '%SW'\n",
    "GROUP BY value);\n",
    "'''\n",
    "\n",
    "QUERY_SW = '''\n",
    "SELECT count(*) AS SW\n",
    "FROM (SELECT value, count(value) as sum\n",
    "FROM node_tags\n",
    "WHERE key = 'street' AND value LIKE '%SE'\n",
    "GROUP BY value);\n",
    "'''\n",
    "\n",
    "no_display='''\n",
    "print return_query(QUERY_NE)\n",
    "print return_query(QUERY_NW)\n",
    "print return_query(QUERY_SE)\n",
    "print return_query(QUERY_SW)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### NE:\n",
    "<p class = 'num'>38</p>\n",
    "\n",
    "#### NW:\n",
    "<p class = 'num'>58</p>\n",
    "\n",
    "#### SE:\n",
    "<p class = 'num'>66</p>\n",
    "\n",
    "#### SW:\n",
    "<p class = 'num'>82</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0    1\n",
      "0    restaurant  422\n",
      "1     fast_food  398\n",
      "2          fuel  190\n",
      "3         bench  182\n",
      "4          cafe  175\n",
      "5          bank  136\n",
      "6      post_box   96\n",
      "7       parking   85\n",
      "8  waste_basket   76\n",
      "9       toilets   73\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT value, count(value) as num\n",
    "FROM node_tags\n",
    "WHERE key = 'amenity'\n",
    "GROUP BY value\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;\n",
    "'''\n",
    "\n",
    "print return_query(QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are more restaurants and fast food places in the city than every other amenity combined. Let's find the most popular types of cuisines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most popular restaurant type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0   1\n",
      "0     chinese  37\n",
      "1  vietnamese  22\n",
      "2    japanese  15\n",
      "3       pizza  15\n",
      "4     italian  14\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT node_tags.value, COUNT(*) as num\n",
    "FROM node_tags\n",
    "    JOIN (SELECT id FROM node_tags WHERE value='restaurant') as i\n",
    "    ON node_tags.id = i.id\n",
    "WHERE node_tags.key='cuisine'\n",
    "GROUP BY node_tags.value\n",
    "ORDER BY num DESC\n",
    "LIMIT 5;\n",
    "'''\n",
    "\n",
    "print return_query(QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the biggest issue with cleaning the dataset of Calgary and surrounding area is a quadrant identifier in addresses that is only required for buildings inside the city boundary. One idea to overcome this issue is to create an additional \"tag\" tag that identifies the quadrant under the node of all addresses inside the City of Calgary's border. There should also be a guideline for entering the quadrant and other frequently used words to ensure consistency and reduce the amount of data cleaning required. The guideline should be a list with accepted values for street names and quadrants. An example guideline would be: \n",
    "\n",
    "########################################\n",
    "#######&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Guideline&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#######\n",
    "########################################<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<u>Accepted Names</u><br>\n",
    "\"Boulevard\"<br>\n",
    "\"Court\"<br>\n",
    "\"Drive\"<br>\n",
    "\"NE\"<br>\n",
    "...\n",
    "\n",
    "Althought not all users would refer to the guideline when entering data, it would create a standard for entering commonly used words and should help in the data cleaning process by reducing the variations in the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerations for adding a quadrant tag\n",
    "\n",
    "The City of Calgary is unique in its area because it is the only municipality that uses a quadrant for every address inside the city. To improve the data in the local dataset and reduce data cleaning efforts, a quadrant identifier tag should be added for all nodes with addresses and the quadrant should be omitted from the address in the \"addr:street\" identifier.\n",
    "\n",
    "#### Benefits\n",
    "<ul>\n",
    "<li>The \"addr:street\" identifier will have the same format ([street name] [street type]) for nodes inside and outside of the city</li>\n",
    "<li>An \"addr:quadrant\" identifier can be queried if user wishes to obtain nodes from specific quadrants of the city.</li>\n",
    "<li>Each quadrant can be seperately queried for data analysis purposes. For example, how many chinese restaurants are in the NE quadrant compared to the NW quadrant.</li>\n",
    "</ul>\n",
    "\n",
    "#### Anticipated Problems\n",
    "<ul>\n",
    "<li>There may be entries that do not include the quadrant in the \"addr:street\" identifier or the \"addr:quadrant\" identifier.</li>\n",
    "<li>The incorrect quadrant might be entered into the \"addr: quadrant\" identifier.</li>\n",
    "<li>Requires extra effort from the user because now they have to split up the address. Will be more difficult for users entering data with bots.</li>\n",
    "</ul>\n",
    "\n",
    "Overall, an extra quadrant tag may require a little more effort from the user and create some scenerios where addresses are entered incorrectly, I think that these problems can be solved with a little due diligence from the user. Having access to the quadrant apart from the street name will allow for much better querying of the data, reduce effort spent in data cleaning, and provide better insight of the city and surrounding areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other details noticed:\n",
    "<ul>\n",
    "    <li>The top 5 users contributed 51% of the data while the other 773 users contributed 49%</li>\n",
    "    <li>Many of the \"key\" and \"value\" tags were entered in all lowercase letters and varying formats for similar entries </li>\n",
    "    <li>The \"city\" key tag is randomly included for some addresses but not others. None of the top 5 contributors added addresses that included the \"city\" key</li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "The above observations lead me to believe that most of the nodes that had user entered data in the \"key\" and \"value\" attributes were manually entered. To improve the quality of the data, there should be a reference guideline on entering street types and other commmon words, as mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The open street map data for the City of Calgary and surrounding areas contains a good overview of the city, although it is far from complete. The map contains the most addresses for the SW quadrant of the city (82) and the least for the NE (38). The data set also contains some addresses of surrounding counties and towns and a First Nation's reserve. Evidence in data entry suggests that most users entered information manually rather than deploying a bot because there are several variances of the same words. Data was suffienctly cleaned for the purposes of this exercise.\n",
    "\n",
    "An interesting observation is that Calgary has a lot of restaurants and fast food places. One reason for this is the economic boom that the city had enjoyed for a long time as the oil and gas capital of Canada. The economic prosperity allowed many residents to have a large disposable income to spend on dining. It will be interesting to see how this number changes over the next several years now that Calgary has been in a recession sinces mid 2014. The recession is a result of the downturn in commidity prices and local businesses have closed as a result.\n",
    "\n",
    "Overall I believe that the OSM data set for Calgary contains accurate information. It can be further improved by standardizing the way that manual user entries are added. Some of the dirty data that is currently in the dataset can also be cleaned using the cleaning functions included in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><a href = \"https://www.udacity.com/course/data-wrangling-with-mongodb--ud032\">Udacity Data Wrangling Course</a></li>\n",
    "<li><a href = \"www.stackoverflow.com\">Stack Overflow</a></li>\n",
    "<li><a href = \"https://regex101.com/#python\">Regular Expressions</a></li>\n",
    "<li><a href = \"www.openstreetmap.org\">Open Street Map</a></li>\n",
    "<li><a href = \"https://gist.github.com/carlward/54ec1c91b62a5f911c42#file-sample_project-md\">Udacity sample project</a></li>\n",
    "\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
